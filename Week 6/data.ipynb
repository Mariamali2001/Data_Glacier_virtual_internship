{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: File Ingestion and Schema validation**\n",
    "\n",
    "Take any csv/text file of 2+ GB of your choice.\n",
    "\n",
    "Read the file ( Present approach of reading the file )\n",
    "\n",
    "Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
    "\n",
    "Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "\n",
    "As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of\n",
    "read and write file, column name in YAML\n",
    "\n",
    "Validate number of columns and column name of ingested file with YAML.\n",
    "\n",
    "Write the file in pipe separated text file (|) in gz format.\n",
    "\n",
    "Create a summary of the file:\n",
    "\n",
    "*  Total number of rows\n",
    "*   total number of columns\n",
    "*   file size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Books Reviews dataset used from kaggle \n",
    "# (10 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859504349"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the date with Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data with Pandas:  30.28435969352722 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start = time.time()\n",
    "pd_data = pd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Read data with Pandas: \",(end-start),\"sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the data with Dask** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data with Dask:  0.00699162483215332 sec\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "\n",
    "start = time.time()\n",
    "dask_data = dd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Read data with Dask: \",(end-start),\"sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the data with Modin and Ray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data with Modin:  3.2011873722076416 sec\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "import modin.pandas as pd\n",
    "\n",
    "start = time.time()\n",
    "modin_data = pd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Read data with Modin: \",(end-start),\"sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask is better than Pandas, Modin and ray with least reading time of 0.010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove underscores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dask_data.columns=dask_data.columns.str.replace('[_]','')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Price', 'Userid', 'profileName', 'review/helpfulness',\n",
       "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create YAML file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import subprocess\n",
    "import yaml\n",
    "import datetime\n",
    "import gc\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Reading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Testutility.py\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream,Loader=yaml.Loader)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string)\n",
    "    return string\n",
    "\n",
    "\n",
    "def col_header_val(df, table_config):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]', '_', regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x, '_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns = list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\", mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\", missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting books.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile books.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: books_rating\n",
    "table_name : edsurv\n",
    "inbound_delimiter : \",\"\n",
    "outbound_delimiter : \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns:\n",
    "  -Id\n",
    "  -Title\n",
    "  -Price\n",
    "  -Userid\n",
    "  -profileName\n",
    "  -review/helpfulness\n",
    "  -review/score\n",
    "  -review/time\n",
    "  -review/summary\n",
    "  -review/text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yaml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\Testutility.py:4\u001b[0m, in \u001b[0;36mread_config_file\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mreturn\u001b[39;00m yaml\u001b[39m.\u001b[39msafe_load(stream,Loader\u001b[39m=\u001b[39myaml\u001b[39m.\u001b[39mLoader)\n\u001b[0;32m      5\u001b[0m \u001b[39mexcept\u001b[39;00m yaml\u001b[39m.\u001b[39mYAMLError \u001b[39mas\u001b[39;00m exc:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yaml' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\data.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mTestutility\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutil\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myaml\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data_config \u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39;49mread_config_file(\u001b[39m\"\u001b[39;49m\u001b[39mbooks.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\Testutility.py:5\u001b[0m, in \u001b[0;36mread_config_file\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m yaml\u001b[39m.\u001b[39msafe_load(stream,Loader\u001b[39m=\u001b[39myaml\u001b[39m.\u001b[39mLoader)\n\u001b[1;32m----> 5\u001b[0m \u001b[39mexcept\u001b[39;00m yaml\u001b[39m.\u001b[39mYAMLError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m      6\u001b[0m     logging\u001b[39m.\u001b[39merror(exc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yaml' is not defined"
     ]
    }
   ],
   "source": [
    "import Testutility as util\n",
    "import yaml\n",
    "\n",
    "data_config =util.read_config_file(\"books.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data of config file\n",
    "data_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
