{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: File Ingestion and Schema validation**\n",
    "\n",
    "Take any csv/text file of 2+ GB of your choice.\n",
    "\n",
    "Read the file ( Present approach of reading the file )\n",
    "\n",
    "Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
    "\n",
    "Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "\n",
    "As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of\n",
    "read and write file, column name in YAML\n",
    "\n",
    "Validate number of columns and column name of ingested file with YAML.\n",
    "\n",
    "Write the file in pipe separated text file (|) in gz format.\n",
    "\n",
    "Create a summary of the file:\n",
    "\n",
    "*  Total number of rows\n",
    "*   total number of columns\n",
    "*   file size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Books Reviews dataset used from kaggle \n",
    "# (10 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859504349"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the date with Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data with Pandas:  59.0678277015686 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start = time.time()\n",
    "pd_data = pd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Read data with Pandas: \",(end-start),\"sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the data with Dask** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data with Dask:  0.1530764102935791 sec\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "\n",
    "start = time.time()\n",
    "dask_data = dd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Read data with Dask: \",(end-start),\"sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the data with Modin and Ray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "import modin.pandas as pd\n",
    "\n",
    "start = time.time()\n",
    "modin_data = pd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Read data with Modin: \",(end-start),\"sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask is better than Pandas, Modin and ray with least reading time of 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "d_data= dd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 10 entries, Id to review/text\n",
      "dtypes: object(6), float64(2), int64(2)"
     ]
    }
   ],
   "source": [
    "d_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove underscores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_data.columns=d_data.columns.str.replace('[_,@,&]','')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove white space from columns\n",
    "d_data.columns = d_data.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Price', 'Userid', 'profileName', 'review/helpfulness',\n",
       "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create YAML file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Reading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Testutility.py\n",
    "import yaml\n",
    "import logging\n",
    "import subprocess\n",
    "import yaml\n",
    "import datetime\n",
    "import gc\n",
    "import re \n",
    "import pandas as pd\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string)\n",
    "    return string\n",
    "\n",
    "\n",
    "def col_header_val(df, table_config):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]', '_', regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x, '_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns = list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\", mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\", missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting books.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile books.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: books_rating\n",
    "table_name : edsurv\n",
    "inbound_delimiter : \",\"\n",
    "outbound_delimiter : \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - Id\n",
    "    - Title\n",
    "    - Price\n",
    "    - Userid\n",
    "    - profileName\n",
    "    - review/helpfulness\n",
    "    - review/score\n",
    "    - review/time\n",
    "    - review/summary\n",
    "    - review/text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Testutility as util\n",
    "\n",
    "data_config =util.read_config_file(\"books.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data of config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'file',\n",
       " 'file_name': 'books_rating',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['Id',\n",
       "  'Title',\n",
       "  'Price',\n",
       "  'Userid',\n",
       "  'profileName',\n",
       "  'review/helpfulness',\n",
       "  'review/score',\n",
       "  'review/time',\n",
       "  'review/summary',\n",
       "  'review/text']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal reading process of the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dask import dataframe as dd\n",
    "df= dd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the file using config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\data.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m file_type \u001b[39m=\u001b[39m data_config[\u001b[39m'\u001b[39m\u001b[39mfile_type\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m source_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m data_config[\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mfile_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(source_file,data_config[\u001b[39m'\u001b[39;49m\u001b[39minbound_delimiter\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_data\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\modin\\logging\\logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[0;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\modin\\pandas\\io.py:140\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    138\u001b[0m _, _, _, f_locals \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetargvalues(inspect\u001b[39m.\u001b[39mcurrentframe())\n\u001b[0;32m    139\u001b[0m kwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m f_locals\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m _pd_read_csv_signature}\n\u001b[1;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m _read(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\modin\\pandas\\io.py:57\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     45\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m    Read csv file from local disk.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m    modin.pandas.DataFrame\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     Engine\u001b[39m.\u001b[39;49msubscribe(_update_engine)\n\u001b[0;32m     58\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexecution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatching\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactories\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m FactoryDispatcher\n\u001b[0;32m     60\u001b[0m     squeeze \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39msqueeze\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\modin\\config\\pubsub.py:213\u001b[0m, in \u001b[0;36mParameter.subscribe\u001b[1;34m(cls, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mAdd `callback` to the `_subs` list and then execute it.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39m    Callable to execute.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_subs\u001b[39m.\u001b[39mappend(callback)\n\u001b[1;32m--> 213\u001b[0m callback(\u001b[39mcls\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\modin\\pandas\\__init__.py:122\u001b[0m, in \u001b[0;36m_update_engine\u001b[1;34m(publisher)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m publisher\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRay\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m _is_first_update\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mRay\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 122\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexecution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize_ray\n\u001b[0;32m    124\u001b[0m         initialize_ray()\n\u001b[0;32m    125\u001b[0m \u001b[39melif\u001b[39;00m publisher\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNative\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# With OmniSci storage format there is only a single worker per node\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[39m# and we allow it to work on all cores.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\modin\\core\\execution\\ray\\common\\__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Licensed to Modin Development Team under one or more contributor license agreements.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# See the NOTICE file distributed with this work for additional information regarding\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# copyright ownership.  The Modin Development Team licenses this file to you under the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# ANY KIND, either express or implied. See the License for the specific language\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# governing permissions and limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m\"\"\"Common utilities for Ray execution engine.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtask_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m RayTask, SignalActor\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize_ray\n\u001b[0;32m     19\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     20\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minitialize_ray\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRayTask\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSignalActor\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\modin\\core\\execution\\ray\\common\\task_wrapper.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mThe module with helper mixin for executing functions remotely.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mTo be used as a piece of building a Ray-based engine.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39masyncio\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m@ray\u001b[39m\u001b[39m.\u001b[39mremote\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deploy_ray_func\u001b[39m(func, args):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m    Wrap `func` to ease calling it remotely.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m        Ray identifier of the result being put to Plasma store.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "\n",
    "file_type = data_config['file_type']\n",
    "source_file = \"./\" + data_config['file_name'] + f'.{file_type}'\n",
    "df_data = pd.read_csv(source_file,data_config['inbound_delimiter'])\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate the header of the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reindex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\data.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m util\u001b[39m.\u001b[39;49mcol_header_val(df_dask,data_config)\n",
      "File \u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\Testutility.py:31\u001b[0m, in \u001b[0;36mcol_header_val\u001b[1;34m(df, table_config)\u001b[0m\n\u001b[0;32m     29\u001b[0m expected_col\u001b[39m.\u001b[39msort()\n\u001b[0;32m     30\u001b[0m df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mlower(), \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)))\n\u001b[1;32m---> 31\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mreindex(\u001b[39msorted\u001b[39m(df\u001b[39m.\u001b[39mcolumns), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(expected_col) \u001b[39mand\u001b[39;00m \u001b[39mlist\u001b[39m(expected_col)  \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcolumn name and column length validation passed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\core.py:4279\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[0;32m   4278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4279\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reindex'"
     ]
    }
   ],
   "source": [
    "\n",
    "util.col_header_val(df,data_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness',\n",
      "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
      "      dtype='object')\n",
      "columns of YAML are: ['Id', 'Title', 'Price', 'Userid', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns of files are:\" ,df.columns)\n",
    "print(\"columns of YAML are:\" ,data_config['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reindex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\data.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m util\u001b[39m.\u001b[39;49mcol_header_val(df,data_config)\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mvalidation failed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\Testutility.py:31\u001b[0m, in \u001b[0;36mcol_header_val\u001b[1;34m(df, table_config)\u001b[0m\n\u001b[0;32m     29\u001b[0m expected_col\u001b[39m.\u001b[39msort()\n\u001b[0;32m     30\u001b[0m df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mlower(), \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)))\n\u001b[1;32m---> 31\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mreindex(\u001b[39msorted\u001b[39m(df\u001b[39m.\u001b[39mcolumns), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(expected_col) \u001b[39mand\u001b[39;00m \u001b[39mlist\u001b[39m(expected_col)  \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcolumn name and column length validation passed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\core.py:4279\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[0;32m   4278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4279\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reindex'"
     ]
    }
   ],
   "source": [
    "if util.col_header_val(df,data_config)==0:\n",
    "    print(\"validation failed\")\n",
    "else:\n",
    "    print(\"col validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+--------+--------+----------+\n| Column | Found  | Expected |\n+--------+--------+----------+\n| Id     | object | int64    |\n+--------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- Id\n  ValueError(\"invalid literal for int() with base 10: 'B000L4056E'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'Id': 'object'}\n\nto the call to `read_csv`/`read_table`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\solo projects\\Data_Glacier_virtual_internship\\Data_Glacier_virtual_internship\\Week 6\\data.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mE:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv\u001b[39m\u001b[39m'\u001b[39m,delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Write csv in gz format in pipe separated text file (|)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39mBooks_rating.csv.gz\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m           sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m|\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m           header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m           index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m           quoting\u001b[39m=\u001b[39;49mcsv\u001b[39m.\u001b[39;49mQUOTE_ALL,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m           compression\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgzip\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m           quotechar\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m           doublequote\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/solo%20projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week%206/data.ipynb#X44sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m           line_terminator\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\core.py:1560\u001b[0m, in \u001b[0;36m_Frame.to_csv\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[39m\"\"\"See dd.to_csv docstring for more information\"\"\"\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m to_csv\n\u001b[1;32m-> 1560\u001b[0m \u001b[39mreturn\u001b[39;00m to_csv(\u001b[39mself\u001b[39m, filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:957\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m         compute_kwargs[\u001b[39m\"\u001b[39m\u001b[39mscheduler\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m scheduler\n\u001b[0;32m    955\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mdask\u001b[39;00m\n\u001b[1;32m--> 957\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(dask\u001b[39m.\u001b[39mcompute(\u001b[39m*\u001b[39mvalues, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcompute_kwargs))\n\u001b[0;32m    958\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    959\u001b[0m     \u001b[39mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\base.py:571\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[0;32m    569\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 571\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    572\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\threaded.py:79\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[0;32m     77\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 79\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[0;32m     80\u001b[0m     pool\u001b[39m.\u001b[39msubmit,\n\u001b[0;32m     81\u001b[0m     pool\u001b[39m.\u001b[39m_max_workers,\n\u001b[0;32m     82\u001b[0m     dsk,\n\u001b[0;32m     83\u001b[0m     result,\n\u001b[0;32m     84\u001b[0m     cache\u001b[39m=\u001b[39mcache,\n\u001b[0;32m     85\u001b[0m     get_id\u001b[39m=\u001b[39m_thread_get_id,\n\u001b[0;32m     86\u001b[0m     pack_exception\u001b[39m=\u001b[39mpack_exception,\n\u001b[0;32m     87\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\local.py:507\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m         _execute_task(task, data)  \u001b[39m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    506\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 507\u001b[0m         raise_exception(exc, tb)\n\u001b[0;32m    508\u001b[0m res, worker_id \u001b[39m=\u001b[39m loads(res_info)\n\u001b[0;32m    509\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m][key] \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\local.py:315\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m    314\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 315\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\local.py:220\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     task, data \u001b[39m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 220\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, data)\n\u001b[0;32m    221\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m get_id()\n\u001b[0;32m    222\u001b[0m     result \u001b[39m=\u001b[39m dumps((result, \u001b[39mid\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\optimization.py:969\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys):\n\u001b[0;32m    968\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m args, got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys), \u001b[39mlen\u001b[39m(args)))\n\u001b[1;32m--> 969\u001b[0m \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdsk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutkey, \u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minkeys, args)))\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\core.py:149\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, out, cache)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m toposort(dsk):\n\u001b[0;32m    148\u001b[0m     task \u001b[39m=\u001b[39m dsk[key]\n\u001b[1;32m--> 149\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, cache)\n\u001b[0;32m    150\u001b[0m     cache[key] \u001b[39m=\u001b[39m result\n\u001b[0;32m    151\u001b[0m result \u001b[39m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:128\u001b[0m, in \u001b[0;36mCSVFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m    125\u001b[0m         rest_kwargs[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m columns\n\u001b[0;32m    127\u001b[0m \u001b[39m# Call `pandas_read_text`\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m df \u001b[39m=\u001b[39m pandas_read_text(\n\u001b[0;32m    129\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreader,\n\u001b[0;32m    130\u001b[0m     block,\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheader,\n\u001b[0;32m    132\u001b[0m     rest_kwargs,\n\u001b[0;32m    133\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtypes,\n\u001b[0;32m    134\u001b[0m     columns,\n\u001b[0;32m    135\u001b[0m     write_header,\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menforce,\n\u001b[0;32m    137\u001b[0m     path_info,\n\u001b[0;32m    138\u001b[0m )\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m project_after_read:\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns]\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:183\u001b[0m, in \u001b[0;36mpandas_read_text\u001b[1;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[0m\n\u001b[0;32m    181\u001b[0m df \u001b[39m=\u001b[39m reader(bio, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m dtypes:\n\u001b[1;32m--> 183\u001b[0m     coerce_dtypes(df, dtypes)\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m enforce \u001b[39mand\u001b[39;00m columns \u001b[39mand\u001b[39;00m (\u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m(columns)):\n\u001b[0;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns do not match\u001b[39m\u001b[39m\"\u001b[39m, df\u001b[39m.\u001b[39mcolumns, columns)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:284\u001b[0m, in \u001b[0;36mcoerce_dtypes\u001b[1;34m(df, dtypes)\u001b[0m\n\u001b[0;32m    280\u001b[0m rule \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m61\u001b[39m)\n\u001b[0;32m    281\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMismatched dtypes found in `pd.read_csv`/`pd.read_table`.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m    282\u001b[0m     rule\u001b[39m.\u001b[39mjoin(\u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, [dtype_msg, date_msg]))\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+--------+--------+----------+\n| Column | Found  | Expected |\n+--------+--------+----------+\n| Id     | object | int64    |\n+--------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- Id\n  ValueError(\"invalid literal for int() with base 10: 'B000L4056E'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'Id': 'object'}\n\nto the call to `read_csv`/`read_table`."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import datetime\n",
    "\n",
    "from dask import dataframe as dd\n",
    "df = dd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv',delimiter=',')\n",
    "\n",
    "# Write csv in gz format in pipe separated text file (|)\n",
    "df.to_csv('Books_rating.csv.gz',\n",
    "          sep='|',\n",
    "          header=True,\n",
    "          index=False,\n",
    "          quoting=csv.QUOTE_ALL,\n",
    "          compression='gzip',\n",
    "          quotechar='\"',\n",
    "          doublequote=True,\n",
    "          line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**number of files in gz format folder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**size of the gz format folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "partitions = os.listdir('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv.gz')\n",
    "for partition in partitions:\n",
    "    print(partition)\n",
    "\n",
    "\n",
    "os.path.getsize('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week 6/Books_rating.csv.gz')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
