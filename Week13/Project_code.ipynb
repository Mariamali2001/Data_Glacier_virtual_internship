{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the challenge for all Pharmaceutical companies is to understand the persistency of drug as per the physician prescription. \n",
    "\n",
    "\n",
    "To solve this problem ABC pharma company approached an analytics company to automate this process of identification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H= pd.read_csv('E:/solo projects/Data_Glacier_virtual_internship/Data_Glacier_virtual_internship/Week08/Healthcare_dataset.csv')\n",
    "data_H.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Data Understanding**\n",
    "(Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Observations: {data_H.shape[0]}')\n",
    "print(f'Number of Features: {data_H.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Object Columns: \", data_H.select_dtypes(include = [\"object\"]).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numerical Columns: \", data_H.select_dtypes(include = [\"int64\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_col = list(data_H.select_dtypes(['object']).columns)\n",
    "print(len(obj_col))\n",
    "obj_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data_H.isna().sum()/len(data_H)*1004\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unique values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.value_counts('Persistency_Flag')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H=data_H.drop_duplicates()\n",
    "data_H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No duplicate found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop id column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_H.drop (['Ptid'], axis=1 , inplace=True)\n",
    "# data_H.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers for numerical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_H.select_dtypes([int, float])\n",
    "\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "for i ,columns in enumerate (df,1):\n",
    "    ax= plt.subplot(5,3,i)\n",
    "    sns.boxplot(data= df , x=df[columns])\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_title(f'Distribution of {columns}')\n",
    "    plt.tight_layout(w_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for Skewness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_D = df.skew().sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'skew':skew_D})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skew was greater than zero so the more weight in the left tail of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms for numeric values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.hist(column='Dexa_Freq_During_Rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H.hist(column='Count_Of_Risks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove outliers by IQR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_H\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count_Of_Risks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxval = data[\"Count_Of_Risks\"].max()\n",
    "print(maxval)\n",
    "\n",
    "minval = data[\"Count_Of_Risks\"].min()\n",
    "print(minval)\n",
    "\n",
    "# Removing Outliers from Count_Of_Risks using IQR\n",
    "Q1 = data[\"Count_Of_Risks\"].quantile(0.25)\n",
    "Q3 = data[\"Count_Of_Risks\"].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "lowqe_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "print(lowqe_bound, upper_bound)\n",
    "\n",
    "\n",
    "data = data[~(\n",
    "    (data[\"Count_Of_Risks\"] < lowqe_bound) | (data[\"Count_Of_Risks\"] > upper_bound))]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dexa_Freq_During_Rx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxval = data[\"Dexa_Freq_During_Rx\"].max()\n",
    "print(maxval)\n",
    "\n",
    "minval = data[\"Dexa_Freq_During_Rx\"].min()\n",
    "print(minval)\n",
    "\n",
    "# Removing Outliers from Dexa_Freq_During_Rx using IQR\n",
    "Q1 = data[\"Dexa_Freq_During_Rx\"].quantile(0.25)\n",
    "Q3 = data[\"Dexa_Freq_During_Rx\"].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "lowqe_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "print(lowqe_bound, upper_bound)\n",
    "\n",
    "\n",
    "data = data[~(\n",
    "    (data[\"Dexa_Freq_During_Rx\"] < lowqe_bound) | (data[\"Dexa_Freq_During_Rx\"] > upper_bound))]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot after remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.select_dtypes([int, float])\n",
    "\n",
    "fig=plt.figure(figsize=(15,15))\n",
    "for i ,columns in enumerate (df,1):\n",
    "    ax= plt.subplot(5,3,i)\n",
    "    sns.boxplot(data= df , x=df[columns])\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_title(f'Distribution of {columns}')\n",
    "    plt.tight_layout(w_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove outliers by Z-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outliers = data_H.select_dtypes([int, float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df2 = data_outliers[(np.abs(stats.zscore(data_outliers)) < 2).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use the data that done by IQR to continue the next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_D = data.select_dtypes([int, float]).skew().sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'skew':skew_D})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt=PowerTransformer(method='yeo-johnson') \n",
    "X_power=pt.fit_transform(data.select_dtypes([int, float]))\n",
    "df=pd.DataFrame(X_power,columns=data.select_dtypes([int, float]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(column='Count_Of_Risks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(column='Dexa_Freq_During_Rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-Persistent have higher records in dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Persistency_Flag\",data=data, dodge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The age_Bucker >75 in Persistent and non-Persistent have higher values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Persistency_Flag\", hue='Age_Bucket', data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Persistency_Flag\", hue='Count_Of_Risks', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Caucasian Race in both persistent and non-Persistent have highest count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot( x='Persistency_Flag', hue='Race',data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not Hispanic is dominant in Persistency_Flag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot( x='Persistency_Flag', hue='Ethnicity', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In all the regions the dominant was Not-Persistent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['Region'], data['Persistency_Flag']).plot(kind='bar', figsize=(15, 6))\n",
    "plt.legend(['Not Persistent', 'Persistent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Female patients are more persistent of a drug than male**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='Persistency_Flag', hue='Gender', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The number of patients without having Dexa scan is higher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplt1 = sns.countplot(x='Dexa_During_Rx', hue='Persistency_Flag', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The ratio of the patients which are stable is much more higher than of the ratio of the improved patients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data[\"Gluco_Record_Prior_Ntm\"], data[\"Gluco_Record_During_Rx\"]).plot(kind='bar', figsize=(15, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all categorical columns\n",
    "\n",
    "\n",
    "convert all categorical columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = data.select_dtypes(['object']).columns\n",
    "\n",
    "data[cat_columns] = data[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check null values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opnion, we need to reduce some of features so these feature will be dropped and hence will have 50 column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns Risk_Type_1_Insulin_Dependent_Diabetes, Risk_Osteogenesis_Imperfecta, Risk_Rheumatoid_Arthritis, Risk_Untreated_Chronic_Hyperthyroidism, Risk_Untreated_Chronic_Hypogonadism, Risk_Untreated_Early_Menopause, Risk_Patient_Parent_Fractured_Their_Hip ,Risk_Smoking_Tobacco, Risk_Chronic_Malnutrition_Or_Malabsorption, Risk_Chronic_Liver_Disease, Risk_Family_History_Of_Osteoporosis ,Risk_Low_Calcium_Intake, Risk_Vitamin_D_Insufficiency, Risk_Poor_Health_Frailty, Risk_Excessive_Thinness, Risk_Hysterectomy_Oophorectomy, Risk_Estrogen_Deficiency, Risk_Immobilization Risk_Recurring_Falls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Risk_Type_1_Insulin_Dependent_Diabetes','Risk_Osteogenesis_Imperfecta','Risk_Rheumatoid_Arthritis',\n",
    "'Risk_Untreated_Chronic_Hyperthyroidism','Risk_Untreated_Chronic_Hypogonadism','Risk_Untreated_Early_Menopause',\n",
    "'Risk_Patient_Parent_Fractured_Their_Hip','Risk_Smoking_Tobacco','Risk_Chronic_Malnutrition_Or_Malabsorption',\n",
    "'Risk_Chronic_Liver_Disease','Risk_Family_History_Of_Osteoporosis','Risk_Low_Calcium_Intake','Risk_Vitamin_D_Insufficiency',\n",
    "'Risk_Poor_Health_Frailty','Risk_Excessive_Thinness','Risk_Hysterectomy_Oophorectomy','Risk_Estrogen_Deficiency'\n",
    ",'Risk_Immobilization','Risk_Recurring_Falls'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Columns:\n",
    "Comorb_Encounter_For_Screening_For_Malignant_Neoplasms,Comorb_Encounter_For_Immunization,Comorb_Encntr_For_General_Exam_W_O_Complaint,\n",
    "_Susp_Or_Reprtd_Dx,Comorb_Vitamin_D_Deficiency,Comorb_Other_Joint_Disorder_Not_Elsewhere_Classified',\n",
    "Comorb_Encntr_For_Oth_Sp_Exam_W_O_Complaint_Suspected_Or_Reprtd_Dx,Comorb_Long_Term_Current_Drug_Therapy, Comorb_Dorsalgia,Comorb_Personal_History_Of_Other_Diseases_And_Conditions,\n",
    "Comorb_Other_Disorders_Of_Bone_Density_And_Structure,Comorb_Disorders_of_lipoprotein_metabolism_and_other_lipidemias,\n",
    "Comorb_Osteoporosis_without_current_pathological_fracture,Comorb_Personal_history_of_malignant_neoplasm,Comorb_Gastro_esophageal_reflux_disease,\n",
    "Concom_Cholesterol_And_Triglyceride_Regulating_Preparations,Concom_Narcotics, Concom_Systemic_Corticosteroids_Plain,\n",
    "Concom_Anti_Depressants_And_Mood_Stabilisers,Concom_Fluoroquinolones, Concom_Cephalosporins,Concom_Macrolides_And_Similar_Types,Concom_Broad_Spectrum_Penicillins, Concom_Anaesthetics_General,Concom_Viral_Vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be two columns have count of them one for columns that start with comorb and one for concom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count_Of_Concomitancy\n",
    "data['Count_Of_Concomitancy'] = data.iloc[:, 37:48].dot(np.ones(data.iloc[:, 37:48].shape[1]))\n",
    "\n",
    "# Count_Of_Comorbidity\n",
    "data['Count_Of_Comorbidity'] = data.iloc[:, 24:36].dot(np.ones(data.iloc[:, 24:36].shape[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Comorb_Encounter_For_Screening_For_Malignant_Neoplasms','Comorb_Encounter_For_Immunization',\n",
    "'Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx',\n",
    "'Comorb_Vitamin_D_Deficiency','Comorb_Other_Joint_Disorder_Not_Elsewhere_Classified',\n",
    "'Comorb_Encntr_For_Oth_Sp_Exam_W_O_Complaint_Suspected_Or_Reprtd_Dx','Comorb_Long_Term_Current_Drug_Therapy', 'Comorb_Dorsalgia',\n",
    "'Comorb_Personal_History_Of_Other_Diseases_And_Conditions','Comorb_Other_Disorders_Of_Bone_Density_And_Structure',\n",
    "'Comorb_Disorders_of_lipoprotein_metabolism_and_other_lipidemias','Comorb_Osteoporosis_without_current_pathological_fracture',\n",
    "'Comorb_Personal_history_of_malignant_neoplasm','Comorb_Gastro_esophageal_reflux_disease','Concom_Cholesterol_And_Triglyceride_Regulating_Preparations',\n",
    "'Concom_Narcotics', 'Concom_Systemic_Corticosteroids_Plain','Concom_Anti_Depressants_And_Mood_Stabilisers',\n",
    "'Concom_Fluoroquinolones', 'Concom_Cephalosporins','Concom_Macrolides_And_Similar_Types',\n",
    "'Concom_Broad_Spectrum_Penicillins', 'Concom_Anaesthetics_General','Concom_Viral_Vaccines'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Models**\n",
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Persistency_Flag']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['Persistency_Flag'],axis = 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= y.values\n",
    "X=x.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lgr= LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "model =lgr.fit(x_train,y_train)\n",
    "y_pred_lgr= model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_score(y_test, y_pred_lgr)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred_lgr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeClassifier()\n",
    "tree_model=tree.fit(x_train, y_train)\n",
    "y_pred_tree=tree_model.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_tree)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=svm.SVC()\n",
    "model_svc= svc.fit(x_train, y_train)\n",
    "y_pred_svc= model_svc.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_svc)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm=GradientBoostingClassifier()\n",
    "gbm_model=gbm.fit(x_train, y_train)\n",
    "y_pred_gbm=gbm_model.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_gbm)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regressor =RandomForestClassifier()\n",
    "\n",
    "#fit the model\n",
    "model_rf =regressor.fit(x_train,y_train)\n",
    "y_pred_rf= model.predict(x_test)\n",
    "accuracy_score(y_test, y_pred_rf)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "knn_model=knn.fit(x_train, y_train)\n",
    "y_pred= knn_model.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "X_scaled=scaler.transform(x_train)\n",
    "test_scaled=scaler.transform(x_test)\n",
    "mlpc=MLPClassifier().fit(X_scaled, y_train)\n",
    "y_pred_networks=mlpc.predict(test_scaled)\n",
    "accuracy_score(y_test, y_pred_networks)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_networks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score1 = model.predict(x_test)\n",
    "y_score2 = model_rf.predict(x_test)\n",
    "y_score3 = tree_model.predict(x_test)\n",
    "y_score4 = model_svc.predict(x_test)\n",
    "y_score5 = knn_model.predict(x_test)\n",
    "y_score6 = gbm_model.predict(x_test)\n",
    "y_score7 = mlpc.predict(test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fpr_lr, tpr_lr, threshold1 = roc_curve(y_test,  y_score1)\n",
    "fpr_rfc, tpr_rfc, threshold1 =roc_curve(y_test,  y_score2)\n",
    "fpr_dtc, tpr_dtc, threshold1 =roc_curve(y_test,  y_score3)\n",
    "fpr_svc, tpr_svc, threshold1 = roc_curve(y_test,  y_score4)\n",
    "fpr_knn, tpr_knn, threshold1 =roc_curve(y_test,  y_score5)\n",
    "fpr_gbm, tpr_gbm, threshold1 =roc_curve(y_test,  y_score6)\n",
    "fpr_mlpc, tpr_mlpc, threshold1 =roc_curve(y_test,  y_score7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic - All Models')\n",
    "plt.plot(fpr_lr, tpr_lr, label = \"Logistic Regression\")\n",
    "plt.plot(fpr_rfc, tpr_rfc, label = \"Random Forest\")\n",
    "plt.plot(fpr_dtc, tpr_dtc, label = \"Tree\")\n",
    "plt.plot(fpr_svc, tpr_svc,  label = \"SVC\")\n",
    "plt.plot(fpr_knn, tpr_knn, label = \"KNN\")\n",
    "plt.plot(fpr_gbm, tpr_gbm, label = \"GBM\")\n",
    "plt.plot(fpr_mlpc, tpr_mlpc, label = \"Neural Network\")\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive  Rate')\n",
    "plt.xlabel('False Negative Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset as train set and test set.\n",
    "\n",
    "We have applied Logistic Regression, KNN, Random Forest Model, Decision Tree, Support Vector Machines, Gradient Boosting Model, and Neural Network Models.\n",
    "\n",
    "we have calculated their accuracy scores and we obtained the following:\n",
    "\n",
    "Gradient Boosting Model is the best fit model to our dataset with accuracy score 79.05.\n",
    "\n",
    "We can apply Logistic Regression and Random Forest since their accuracy score 78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
